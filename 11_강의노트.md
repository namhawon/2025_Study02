## Scikit-learn 머신러닝 강의노트 🤖

---

### 학습목표

* Scikit-learn 라이브러리의 역할과 주요 기능을 이해합니다.
* 머신러닝의 기본 워크플로우(데이터 로드, 전처리, 모델 학습, 예측, 평가)를 Scikit-learn으로 수행할 수 있습니다.
* 대표적인 지도 학습 알고리즘(분류, 회귀)을 Scikit-learn을 통해 구현하는 방법을 익힙니다.
* 데이터 분할 및 모델 평가의 중요성을 이해하고 적용할 수 있습니다.

---

### 💡 핵심개념

* **Estimator API:** Scikit-learn의 핵심 인터페이스로, 모든 머신러닝 모델은 일관된 메서드(`fit()`, `predict()`, `transform()`)를 제공합니다.
    * `fit(X, y)`: 모델을 학습 데이터 `X`와 타겟 `y`로 학습시킵니다.
    * `predict(X)`: 학습된 모델을 사용하여 새로운 데이터 `X`의 결과를 예측합니다.
    * `transform(X)`: 데이터를 변환합니다 (주로 전처리 단계에서 사용).
    * `fit_transform(X, y)`: `fit()`과 `transform()`을 순차적으로 적용합니다.
* **데이터셋 (Datasets):** Scikit-learn은 내장된 예제 데이터셋 (예: `iris`, `digits`, `boston_housing`)과 사용자 정의 데이터셋 로딩 기능을 제공합니다.
    * **특성 (Features):** 입력 변수, 독립 변수 (보통 `X`로 표현).
    * **타겟 (Target) / 레이블 (Label):** 예측하려는 값, 종속 변수 (보통 `y`로 표현).
* **데이터 전처리 (Preprocessing):** 머신러닝 모델의 성능을 높이기 위해 원시 데이터를 적절한 형태로 변환하는 과정입니다. (예: `StandardScaler`, `MinMaxScaler`, `OneHotEncoder`)
* **모델 선택 (Model Selection):** 주어진 문제에 가장 적합한 머신러닝 모델을 선택하고, 모델의 하이퍼파라미터를 튜닝하는 과정입니다.
    * `train_test_split`: 데이터를 학습용과 테스트용으로 분리합니다.
* **지도 학습 (Supervised Learning):** 입력(특성)과 정답(타겟)이 있는 데이터를 사용하여 모델을 학습시키는 방법입니다.
    * **분류 (Classification):** 데이터를 미리 정의된 여러 범주 중 하나로 예측합니다. (예: 스팸 메일 분류, 품종 분류)
    * **회귀 (Regression):** 연속적인 값을 예측합니다. (예: 주택 가격 예측, 주가 예측)
* **비지도 학습 (Unsupervised Learning):** 정답(타겟) 없이 입력 데이터만으로 데이터의 숨겨진 구조나 패턴을 찾는 방법입니다. (예: 군집화, 차원 축소)

---

### 🔍 이론 설명

**Scikit-learn이란?**

**Scikit-learn (사이킷런)**은 파이썬 프로그래밍 언어를 위한 **오픈소스 머신러닝 라이브러리**입니다. NumPy, SciPy, Matplotlib을 기반으로 하며, 다양한 머신러닝 알고리즘과 데이터 전처리, 모델 선택 및 평가 도구를 제공하여 사용자가 쉽고 효율적으로 머신러닝 모델을 개발할 수 있도록 지원합니다.

**주요 기능 및 특징:**

* **다양한 알고리즘:** 분류, 회귀, 군집, 차원 축소 등 광범위한 머신러닝 알고리즘을 포함합니다.
* **일관된 API:** 모든 알고리즘이 `Estimator`라는 일관된 인터페이스를 따르므로 사용하기 쉽습니다.
* **데이터 전처리:** 결측치 처리, 특성 스케일링, 범주형 데이터 인코딩 등 다양한 전처리 기능을 제공합니다.
* **모델 선택 및 평가:** 교차 검증, 하이퍼파라미터 튜닝, 성능 지표 계산 등 모델의 성능을 객관적으로 평가하고 최적화하는 도구를 제공합니다.
* **파이프라인 (Pipeline):** 여러 단계를 연결하여 전체 머신러닝 워크플로우를 자동화할 수 있습니다.

**머신러닝 기본 워크플로우 (Scikit-learn 기준):**

1.  **문제 정의 및 데이터 수집:** 해결하고자 하는 문제를 명확히 하고, 관련된 데이터를 수집합니다.
2.  **데이터 준비 및 탐색:**
    * **데이터 로드:** Scikit-learn의 내장 데이터셋을 사용하거나 외부 데이터를 불러옵니다.
        * 예: `from sklearn.datasets import load_iris`
    * **데이터 탐색 (EDA):** 데이터의 구조, 분포, 결측치 등을 확인합니다. (Pandas, Matplotlib, Seaborn 등 활용)
3.  **데이터 전처리:**
    * 결측치 처리, 이상치 제거
    * **특성 스케일링:** `StandardScaler` (평균 0, 분산 1), `MinMaxScaler` (0과 1 사이) 등
    * 범주형 데이터 인코딩: `LabelEncoder`, `OneHotEncoder` 등
4.  **데이터 분할:**
    * `from sklearn.model_selection import train_test_split`
    * `X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)`
    * 학습 데이터 (Training data): 모델 학습에 사용
    * 테스트 데이터 (Test data): 학습된 모델의 성능 평가에 사용
5.  **모델 선택 및 학습:**
    * 문제 유형(분류/회귀)에 맞는 모델을 선택합니다.
        * 분류 예: `from sklearn.neighbors import KNeighborsClassifier`
        * 회귀 예: `from sklearn.linear_model import LinearRegression`
    * 모델 객체를 생성합니다. `model = KNeighborsClassifier(n_neighbors=3)`
    * 학습 데이터를 사용하여 모델을 학습시킵니다. `model.fit(X_train, y_train)`
6.  **모델 예측:**
    * 학습된 모델을 사용하여 테스트 데이터의 타겟 값을 예측합니다. `y_pred = model.predict(X_test)`
7.  **모델 평가:**
    * 예측값(`y_pred`)과 실제 테스트 데이터의 타겟값(`y_test`)을 비교하여 모델의 성능을 평가합니다.
        * 분류 평가 지표: `accuracy_score`, `precision_score`, `recall_score`, `f1_score`, `roc_auc_score` (from `sklearn.metrics`)
        * 회귀 평가 지표: `mean_squared_error`, `r2_score` (from `sklearn.metrics`)
        * 예: `from sklearn.metrics import accuracy_score`
              `accuracy = accuracy_score(y_test, y_pred)`
8.  **모델 개선 (필요시):** 하이퍼파라미터 튜닝 (예: `GridSearchCV`), 특성 공학 등을 통해 모델 성능을 개선합니다.

**예시: 붓꽃(Iris) 품종 분류**

붓꽃 데이터셋은 세 가지 품종(Setosa, Versicolor, Virginica)의 붓꽃에 대한 꽃받침 길이/너비, 꽃잎 길이/너비 정보를 담고 있습니다. 이 정보를 바탕으로 붓꽃의 품종을 예측하는 분류 문제를 Scikit-learn으로 해결할 수 있습니다.

---

### 💻 실습: 붓꽃 품종 분류 (K-최근접 이웃 알고리즘 사용)

이 실습에서는 Scikit-learn을 사용하여 붓꽃 데이터를 불러오고, K-최근접 이웃(K-Nearest Neighbors, KNN) 알고리즘으로 품종을 분류하는 모델을 만들어보겠습니다.

**1단계: 필요한 라이브러리 임포트**

```python
import sklearn
from sklearn.datasets import load_iris # 붓꽃 데이터셋 로더
from sklearn.model_selection import train_test_split # 데이터 분할 함수
from sklearn.neighbors import KNeighborsClassifier # KNN 분류 모델
from sklearn.metrics import accuracy_score # 정확도 평가 함수
import pandas as pd # 데이터프레임 사용 (선택 사항)
import numpy as np # 넘파이 사용 (선택 사항)

# Scikit-learn 버전 확인 (선택 사항)
print(f"Scikit-learn 버전: {sklearn.__version__}")
```

**2단계: 데이터셋 로드 및 확인**

```python
# 붓꽃 데이터셋 로드
iris = load_iris()

# 데이터셋은 딕셔너리 형태와 유사한 Bunch 객체로 구성됨
# print(iris) # 전체 데이터 구조 확인

# 특성 데이터 (X)
X = iris.data
# print("특성 데이터 (처음 5개):\n", X[:5])
# print("특성 데이터의 크기:", X.shape) # (샘플 수, 특성 수)

# 타겟 데이터 (y) - 품종 (0: Setosa, 1: Versicolor, 2: Virginica)
y = iris.target
# print("\n타겟 데이터 (처음 5개):\n", y[:5])
# print("타겟 데이터의 크기:", y.shape) # (샘플 수,)

# 특성 이름
# print("\n특성 이름:", iris.feature_names)

# 타겟 이름
# print("\n타겟 이름:", iris.target_names)

# 데이터를 DataFrame으로 만들어 확인 (선택 사항)
df = pd.DataFrame(data=X, columns=iris.feature_names)
df['target'] = y
df['species'] = df['target'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})
print("\n데이터 프레임 (처음 5개):")
print(df.head())
```

**3단계: 학습 데이터와 테스트 데이터 분할**

모델을 학습시키기 전에 데이터를 학습용과 테스트용으로 분리합니다. 이는 모델이 보지 않은 새로운 데이터에 대해 얼마나 잘 일반화하는지 평가하기 위함입니다.

```python
# 데이터를 학습용(train)과 테스트용(test)으로 분할
# test_size=0.2: 전체 데이터 중 20%를 테스트 데이터로 사용
# random_state: 재현성을 위해 난수 시드 고정 (같은 숫자를 쓰면 항상 같은 방식으로 분할됨)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"\n학습 데이터 크기: X_train {X_train.shape}, y_train {y_train.shape}")
print(f"테스트 데이터 크기: X_test {X_test.shape}, y_test {y_test.shape}")
```

**4단계: K-최근접 이웃(KNN) 모델 생성 및 학습**

K-최근접 이웃 알고리즘은 새로운 데이터 포인트가 주어졌을 때, 기존 학습 데이터 중 가장 가까운 K개의 이웃 데이터의 클래스를 참조하여 해당 데이터의 클래스를 예측하는 단순하면서도 강력한 알고리즘입니다.

```python
# KNN 분류기 모델 객체 생성
# n_neighbors: 참고할 이웃의 수 (하이퍼파라미터)
knn_model = KNeighborsClassifier(n_neighbors=3)

# 학습 데이터를 사용하여 모델 학습
# fit(특성 데이터, 타겟 데이터)
knn_model.fit(X_train, y_train)

print("\nKNN 모델 학습 완료!")
```

**5단계: 테스트 데이터로 예측 수행**

학습된 모델을 사용하여 테스트 데이터의 품종을 예측합니다.

```python
# 테스트 데이터로 예측 수행
y_pred = knn_model.predict(X_test)

print("\n테스트 데이터에 대한 예측 결과 (처음 5개):", y_pred[:5])
print("실제 테스트 데이터의 타겟 값 (처음 5개):", y_test[:5])
```

**6단계: 모델 성능 평가**

예측 결과와 실제 값을 비교하여 모델의 정확도를 평가합니다.

```python
# 정확도(accuracy) 계산
accuracy = accuracy_score(y_test, y_pred)

print(f"\n모델 정확도: {accuracy:.4f}") # 소수점 4자리까지 표시

# 몇 가지 예측 결과와 실제 값 비교
print("\n예측 vs 실제 (일부 샘플):")
for i in range(min(5, len(X_test))): # 최대 5개 또는 테스트 샘플 수만큼 출력
    predicted_species = iris.target_names[y_pred[i]]
    actual_species = iris.target_names[y_test[i]]
    print(f"  샘플 {i+1}: 예측 - {predicted_species}, 실제 - {actual_species}")
```

**7단계 (선택 사항): 새로운 데이터 예측**

학습된 모델을 사용하여 완전히 새로운 데이터에 대한 예측도 가능합니다.

```python
# 예시: 꽃받침 길이 5.0cm, 꽃받침 너비 3.5cm, 꽃잎 길이 1.5cm, 꽃잎 너비 0.2cm 인 붓꽃
new_flower_data = np.array([[5.0, 3.5, 1.5, 0.2]]) # 2차원 배열 형태로 입력

# 새로운 데이터 예측
predicted_class = knn_model.predict(new_flower_data)
predicted_species_name = iris.target_names[predicted_class[0]]

print(f"\n새로운 붓꽃 데이터 {new_flower_data} 의 예측 품종: {predicted_species_name} (클래스: {predicted_class[0]})")
```

이것으로 Scikit-learn을 이용한 간단한 머신러닝 실습을 마칩니다. 이 기본 워크플로우를 이해하면 다른 알고리즘과 데이터셋에도 쉽게 적용할 수 있습니다.
